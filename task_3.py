# -*- coding: utf-8 -*-
"""Task_3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1V5zzjU9VYU3zdlaZcY-ft56lixHh7FOX
"""

import pandas as pd

from google.colab import files
files.upload()

df = pd.read_csv("/content/Binary predictors.csv")

df

dir(pd)

df1 = pd.read_json("/content/sample_data/anscombe.json")

df1

import numpy as np

data = {'animal': ['cat', 'cat', 'snake', 'dog', 'dog', 'cat', 'snake', 'cat', 'dog', 'dog'],
        'age': [2.5, 3, 0.5, np.nan, 5, 2, 4.5, np.nan, 7, 3],
        'visits': [1, 3, 2, 3, 2, 3, 1, 1, 2, 1],
        'priority': ['yes', 'yes', 'no', 'yes', 'no', 'no', 'no', 'yes', 'no', 'no']}

df.info()

df.describe()

df3 = pd.DataFrame(data)

df3

df3.describe()

df3.iloc[0]

df3.iloc[0:7]

df3.iloc[5:7]

df3.iloc[::-1]

df3.iloc[::2]

df3.loc[:,["age","animal"]]

df3.loc[1,["age","animal"]]

df3[["animal"]]

df3[df3["age"]>5]

df3[df3["age"]>=5]

df3[df3["age"].between(3,6)]

df4 = df3[df3["age"].between(3,6)]

df4["animal"]

df3[df3["age"].between(3,6)]["animal"]

df3[(df3["animal"]== "dog")&(df3["age"]>3)]

df

df3

df3.loc[4,"animal"]= "tiger"

df3

df3.loc[2:5, "age"]=7
df3

df3.groupby("animal")["age"].mean()

df3.groupby("priority")["visits"].mean()

df3 = df3.drop(9)
df3

df3["priority"].value_counts()

df3["age"].value_counts()

df3.sort_values(by=["age"],ascending=[True])

df3.sort_values(by=["animal","age"],ascending=[True,True])

df3.sort_values(by=["visits","age","animal"],ascending=[False,True,False])

df3.sort_values(by=["visits","age","animal"],ascending=[True,False,True])

df3.sort_values(by=["age","visits","animal"],ascending=[True,False,True])

df3.sort_values(by=["age","visits","animal"],na_position="first")

df3.sort_values(by=["age"],ascending=[True])

df3["animal"]=df3["animal"].replace("cat","pig")
df3

df3.sort_values(by=["age","visits","animal"],ascending=[True,False,False])

df3["priority"]=df3["priority"].replace("yes","YES")
df3

df3 = df3.drop("dog",1)
df3

df5 = pd.read_csv("/content/Binary predictors.csv")
df5

df5["Admitted"]=df5["Admitted"].map({"Yes":1,"No":0})
df5

df5["Gender"]=df5["Gender"].map({"Male":1,"Female":0})
df5

df6 = pd.read_csv("/content/SAMPLE.csv")
df6

df6.isnull()

df6.isnull().sum()

df6.fillna(45)

df6.fillna(method="ffill") #forward fill

df6.fillna(method="bfill") #forward fill

df6.isna() #checks where null values are

df6.notna()

df6.dropna()  #even if one data is null entire row will be dropped

df6.dropna(how="all") # drop only recors where entire row is null

df6.dropna(how = "any")

df6.dropna(axis = "columns", how = "all")          #column wise filteration of null values

df6.dropna(subset=["name"])

df6.dropna(subset=["hsc"]) #if null exists anu null in that row then the whole row will be deleted

df6

df6.dropna(subset=["hsc","SSLC"]) #removes the entire row if any one of the field has null

df6[df6["arrears"]==0]

x = df6["SSLC"].mean()
x

df6["SSLC"].fillna(value = x ,inplace= True)
df6

df7 = df6.fillna(method="bfill")
df7

#working with duplicates
df7.duplicated()

df7.duplicated(keep="first")

df7.duplicated(keep="first")

df7.duplicated(keep=False) # gives true to all duplicate values.doestnt take anything as original to verify the duplicate with

df7.drop_duplicates(subset=["college"])

df7.drop_duplicates(subset=["college"],keep ="last")

df7.drop_duplicates(subset=["college"],keep =False) #deletes every dulpicate value and retain only unique value

df8 = df6.fillna(method="ffill")
df8

df8.drop_duplicates(subset=["college"],keep =False)

df7.drop_duplicates(subset=["college","name"]) #this works as a "and" condition where only if both records of the colums are repeated only then it will be removed







